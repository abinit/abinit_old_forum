<!DOCTYPE html>
<html dir="ltr" lang="en-gb">

<!-- Mirrored from forum.abinit.org/viewtopic.php?f=3&t=2729&view=print by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 21 Sep 2024 01:00:29 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="robots" content="noindex" />

<title>ABINIT Discussion Forums &bull; Problem with cuda</title>

<link href="styles/flat-style/theme/print.css" rel="stylesheet">
<link href="styles/flat-style/theme/bidi.css" rel="stylesheet">
</head>
<body id="phpbb" class="ltr">
<div id="wrap" class="wrap">
	<a id="top" class="top-anchor" accesskey="t"></a>

	<div id="page-header">
		<h1>ABINIT Discussion Forums</h1>
		<p>The meeting place for ABINIT users and developers<br /><a href="index.html">https://forum.abinit.org/</a></p>

		<h2>Problem with cuda</h2>
		<p><a href="viewtopic7953.html?f=3&amp;t=2729">https://forum.abinit.org/viewtopic.php?f=3&amp;t=2729</a></p>
	</div>

	<div id="page-body" class="page-body">
		<div class="page-number">Page <strong>1</strong> of <strong>1</strong></div>
					<div class="post">
				<h3>Problem with cuda</h3>
				<div class="date">Posted: <strong>Thu Jul 10, 2014 8:14 am</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">Hi I am configuring Abinit 7.6.4 using gcc 4.9.0 with cuda 6.0. Below is the configuration I use:<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>enable_64bit_flags=&quot;yes&quot;<br />enable_mpi=&quot;yes&quot;<br />enable_mpi_io=&quot;yes&quot;<br />enable_openmp=&quot;yes&quot;<br />with_mpi_prefix=&quot;/usr/estools/openmpi/1.8.1/gcc4.9.0&quot;<br />with_netcdf_incs=&quot;-I/usr/estools/netcdf/4.3.2/include&quot;<br />with_netcdf_libs=&quot;-L/usr/estools/netcdf/4.3.2/lib -lnetcdf -lnetcdff&quot;<br />with_etsf_io_incs=&quot;-I/usr/estools/etsf_io/1.0.4/include/gcc&quot;<br />with_etsf_io_libs=&quot;-L/usr/estools/etsf_io/1.0.4/lib -letsf_io_low_level -letsf_io_utils -letsf_io&quot;<br />with_fft_flavor=&quot;fftw3-mpi&quot;<br />with_fft_incs=&quot;-I/usr/estools/fftw/3.3.4/include&quot;<br />with_fft_libs=&quot;-L/usr/estools/fftw/3.3.4/lib -lfftw3 -lfftw3f -lfftw3_mpi -lfftw3f_mpi&quot;<br />with_linalg_flavor=&quot;atlas+magma+scalapack&quot;<br />with_linalg_incs=&quot;-I/usr/estools/ScaLAPACK/include -I/usr/estools/magma/1.5.0-beta2/include -I/usr/estools/ATLAS/3.10.1/include&quot;<br />with_linalg_libs=&quot;-L/usr/estools/ScaLAPACK/lib -lscalapack -L/usr/estools/magma/1.5.0-beta2/lib -lmagma -L/usr/estools/ATLAS/3.10.1/lib -llapack -lf77blas -lcblas -latlas&quot;<br />with_algo_incs=&quot;-I/usr/estools/levmar/2.6/include&quot;<br />with_algo_libs=&quot;-L/usr/estools/levmar/2.6/lib -llevmar -L/usr/estools/ATLAS/3.10.1/lib -llapack -lf77blas -lcblas -latlas&quot;<br />with_math_incs=&quot;-I/usr/estools/gsl/1.16/include&quot;<br />with_math_libs=&quot;-L/usr/estools/gsl/1.16/lib -lgsl -lgslcblas&quot;<br />with_atompaw_bins=&quot;/usr/estools/atompaw/4.0.0.8/bin&quot;<br />with_atompaw_incs=&quot;-I/usr/estools/atompaw/4.0.0.8/include&quot;<br />with_atompaw_libs=&quot;-L/usr/estools/atompaw/4.0.0.8/lib -latompaw&quot;<br />with_bigdft_incs=&quot;-I/usr/estools/bigdft/1.7.1/include&quot;<br />with_bigdft_libs=&quot;-L/usr/estools/libarchive/3.1.2/lib -larchive -L/usr/estools/bigdft/1.7.1/lib -lyaml -ls_gpu -lbigdft-1 -labinit -L/usr/estools/etsf_io/1.0.4/lib -letsf_io_low_level -letsf_io_utils -letsf_io -L/usr/estools/netcdf/4.3.2/lib -lnetcdf -lnetcdff -L/usr/local/cuda-6.0/lib64 -lcublas -lcufft -lcudart&quot;<br />with_libxc_incs=&quot;-I/usr/estools/libxc/2.0.2/include&quot;<br />with_libxc_libs=&quot;-L/usr/estools/libxc/2.0.2/lib -lxc&quot;<br />with_wannier90_bins=&quot;/usr/estools/wannier90/2.0.0/bin&quot;<br />with_wannier90_incs=&quot;-I/usr/estools/wannier90/2.0.0/include&quot;<br />with_wannier90_libs=&quot;-L/usr/estools/wannier90/2.0.0/lib -lwannier&quot;<br />with_dft_flavor=&quot;atompaw+bigdft+libxc+wannier90&quot;<br />with_trio_flavor=&quot;netcdf+etsf_io&quot;<br />with_algo_flavor=&quot;levmar&quot;<br />with_math_flavor=&quot;gsl&quot;<br />enable_gw_dpc=&quot;yes&quot;<br />enable_gpu=&quot;yes&quot;<br />with_gpu_flavor=&quot;cuda-double&quot;<br />with_gpu_incs=&quot;-I/usr/local/cuda-6.0/include&quot;<br />with_gpu_libs=&quot;-L/usr/local/cuda-6.0/lib64 -lcublas -lcufft -lcudart&quot;<br /></code></pre></div><br /><br />Configure step can be completed successfully. However i encounter error with abinit-7.6.4/src/15_gpu_toolbox/ during the make process:<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>../../../abinit-7.6.4/src/15_gpu_toolbox/dev_spec.cu(19): warning: function &quot;prt_dev_info&quot; was declared but never referenced<br /><br />../../../abinit-7.6.4/src/incs/cuda_header.h(58): error: identifier &quot;sprintf&quot; is undefined<br /><br />1 error detected in the compilation of &quot;/tmp/tmpxft_00000751_00000000-6_gpu_linalg.cpp1.ii&quot;.<br />../../../abinit-7.6.4/src/incs/cuda_header.h(58): error: identifier &quot;sprintf&quot; is undefined<br /><br />../../../abinit-7.6.4/src/15_gpu_toolbox/timing_cuda.cu(42): error: identifier &quot;printf&quot; is undefined<br /><br />../../../abinit-7.6.4/src/15_gpu_toolbox/timing_cuda.cu(57): error: identifier &quot;printf&quot; is undefined<br /><br />3 errors detected in the compilation of &quot;/tmp/tmpxft_00000758_00000000-6_timing_cuda.cpp1.ii&quot;.<br />make&#91;4&#93;: *** &#91;gpu_linalg.o&#93; Error 2<br />make&#91;4&#93;: *** Waiting for unfinished jobs....<br />make&#91;4&#93;: *** &#91;timing_cuda.o&#93; Error 2<br />../../../abinit-7.6.4/src/15_gpu_toolbox/dev_spec.cu(19): warning: function &quot;prt_dev_info&quot; was declared but never referenced<br /><br />make&#91;4&#93;: Leaving directory `/home/sheng/Desktop/program/Abinit/abinit-7.6.4-build/src/15_gpu_toolbox'<br />make&#91;3&#93;: *** &#91;all-recursive&#93; Error 1<br />make&#91;3&#93;: Leaving directory `/home/sheng/Desktop/program/Abinit/abinit-7.6.4-build/src'<br />make&#91;2&#93;: *** &#91;all-recursive&#93; Error 1<br />make&#91;2&#93;: Leaving directory `/home/sheng/Desktop/program/Abinit/abinit-7.6.4-build'<br />make&#91;1&#93;: *** &#91;all&#93; Error 2<br />make&#91;1&#93;: Leaving directory `/home/sheng/Desktop/program/Abinit/abinit-7.6.4-build'<br />make: *** &#91;multi&#93; Error 2<br /></code></pre></div><br /><br />Did I do anything wrong?</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Sat Jul 12, 2014 11:32 am</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">I have solved the mentioned problem simply by adding header files<br />#include &lt;stdio.h&gt;<br />to abinit-7.6.4/src/incs/cuda_header.h and abinit-7.6.4/src/15_gpu_toolbox/timing_cuda.cu.<br /><br />However new errors appear:<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:79.20:<br /><br />&nbsp; &nbsp;wvl%atoms%geocode = 'P'<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'geocode' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:81.20:<br /><br />&nbsp; &nbsp;wvl%atoms%geocode = 'F'<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'geocode' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:83.20:<br /><br />&nbsp; &nbsp;wvl%atoms%geocode = 'S'<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'geocode' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:85.22:<br /><br />&nbsp;write(wvl%atoms%units, &quot;(A)&quot;) &quot;Bohr&quot;<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: Syntax error in WRITE statement at (1)<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:91.28:<br /><br />&nbsp; &nbsp;write(wvl%atoms%atomnames(itype), &quot;(A,I2)&quot;) &quot;At. type&quot;, itype<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: Syntax error in WRITE statement at (1)<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:93.16:<br /><br />&nbsp;wvl%atoms%alat1&nbsp; &nbsp; =&nbsp; acell(1)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'alat1' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:94.16:<br /><br />&nbsp;wvl%atoms%alat2&nbsp; &nbsp; =&nbsp; acell(2)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'alat2' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:95.16:<br /><br />&nbsp;wvl%atoms%alat3&nbsp; &nbsp; =&nbsp; acell(3)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'alat3' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:96.17:<br /><br />&nbsp;wvl%atoms%iatype&nbsp; &nbsp;= typat<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: 'iatype' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:110.14:<br /><br />&nbsp;wvl%atoms%sym%symObj = 0<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:111.22:<br /><br />&nbsp;nullify(wvl%atoms%sym%irrzon)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set.F90:112.22:<br /><br />&nbsp;nullify(wvl%atoms%sym%phnons)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/nullify_wvl_data.F90:54.23:<br /><br />&amp; nullify_diis_objects, nullify_wfn_metadata, nullify_p2pcomms,&amp;<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: Symbol 'nullify_wfn_metadata' referenced at (1) not found in module 'bigdft_api'<br />../../../abinit-7.6.4/src/43_wvl_wrappers/nullify_wvl_data.F90:108.43:<br /><br />&nbsp;call nullify_wfn_metadata(wvl%wfs%ks%wfnmd)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: 'wfnmd' at (1) is not a member of the 'dft_wavefunction' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/nullify_wvl_data.F90:110.39:<br /><br />&nbsp;call nullify_p2pcomms(wvl%wfs%ks%comon)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: 'comon' at (1) is not a member of the 'dft_wavefunction' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/nullify_wvl_data.F90:116.39:<br /><br />&nbsp;call nullify_p2pcomms(wvl%wfs%ks%comrp)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: 'comrp' at (1) is not a member of the 'dft_wavefunction' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/nullify_wvl_data.F90:118.39:<br /><br />&nbsp;call nullify_p2pcomms(wvl%wfs%ks%comsr)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: 'comsr' at (1) is not a member of the 'dft_wavefunction' structure<br />make&#91;4&#93;: *** &#91;nullify_wvl_data.o&#93; Error 1<br />make&#91;4&#93;: *** Waiting for unfinished jobs....<br />make&#91;4&#93;: *** &#91;wvl_descr_atoms_set.o&#93; Error 1<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_denspot_set.F90:115.66:<br /><br />&nbsp;call denspot_communications(me,nproc,ixc,nsppol,wvl%atoms%geocode,&quot;NONE&quot;,den%d<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'geocode' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_denspot_set.F90:127.27:<br /><br />&nbsp;den%symObj = wvl%atoms%sym%symObj<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set_sym.F90:98.14:<br /><br />&nbsp;wvl%atoms%sym%symObj = -1<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set_sym.F90:99.22:<br /><br />&nbsp;nullify(wvl%atoms%sym%irrzon)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set_sym.F90:100.22:<br /><br />&nbsp;nullify(wvl%atoms%sym%phnons)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set_sym.F90:103.40:<br /><br />&nbsp; &nbsp;call symmetry_set_n_sym(wvl%atoms%sym%symObj, nsym, symrel, tnons, symafm, e<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set_sym.F90:105.14:<br /><br />&nbsp;wvl%atoms%sym%irrzon =&gt; irrzon<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_descr_atoms_set_sym.F90:106.14:<br /><br />&nbsp;wvl%atoms%sym%phnons =&gt; phnons<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1<br />Error: 'sym' at (1) is not a member of the 'atoms_data' structure<br />make&#91;4&#93;: *** &#91;wvl_denspot_set.o&#93; Error 1<br />make&#91;4&#93;: *** &#91;wvl_descr_atoms_set_sym.o&#93; Error 1<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_denspot_free.F90:42.5:<br /><br />&nbsp;use defs_wvltypes<br />&nbsp; &nbsp; &nbsp;1<br />Warning: Although not referenced, 'generic interface 'memocc'' has ambiguous interfaces at (1)<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_denspot_free.F90:77.9:<br /><br />&nbsp;nullify(den%denspot%pkernel)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: Non-POINTER in pointer association context (pointer assignment) at (1)<br />../../../abinit-7.6.4/src/43_wvl_wrappers/wvl_denspot_free.F90:78.9:<br /><br />&nbsp;nullify(den%denspot%pkernelseq)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: Non-POINTER in pointer association context (pointer assignment) at (1)<br />make&#91;4&#93;: *** &#91;wvl_denspot_free.o&#93; Error 1<br />make&#91;4&#93;: Leaving directory `/home/sheng/Desktop/program/Abinit/abinit-7.6.4-build/src/43_wvl_wrappers'<br />make&#91;3&#93;: *** &#91;all-recursive&#93; Error 1<br />make&#91;3&#93;: Leaving directory `/home/sheng/Desktop/program/Abinit/abinit-7.6.4-build/src'<br />make&#91;2&#93;: *** &#91;all-recursive&#93; Error 1<br />make&#91;2&#93;: Leaving directory `/home/sheng/Desktop/program/Abinit/abinit-7.6.4-build'<br />make&#91;1&#93;: *** &#91;all&#93; Error 2<br />make&#91;1&#93;: Leaving directory `/home/sheng/Desktop/program/Abinit/abinit-7.6.4-build'<br />make: *** &#91;multi&#93; Error 2<br /></code></pre></div><br /><br />Any help is appreciated.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Mon Jul 14, 2014 10:20 am</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">The above seems to be avoided in the latest Abinit 7.8.1, only to end at another error:<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>../../../abinit-7.8.1/src/98_main/mrgscr.F90:2386.51:<br /><br />!$OMP&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PRIVATE(ig1,ig2,refval,imfval,phase)<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1<br />Error: Object 'one' is not a variable at (1)<br /></code></pre></div><br /><br />update: the error seems to be associated with levmar. I can finish building abinit by dropping levmar support.<br /><br />Without levmar support, I have built abinit and try to run the test ./runtests.py -t0 -j 4 fast. <br />As usual some errors comes out again. All test sections fail and I list down the error for one section below:<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>&#91;fast&#93;&#91;t16&#93;&#91;np=1&#93;: fldiff.pl fatal error:<br />The diff analysis cannot be done: the number of lines to be analysed differ.<br />File /home/sheng/Desktop/program/Abinit/abinit-7.8.1/tests/fast/Refs/t16.out: 103 lines, 18 ignored<br />File /home/sheng/Desktop/program/Abinit/abinit-7.8.1-build/tests/Test_suite/fast_t03-t05-t06-t07-t08-t09-t11-t12-t14-t16/t16.out: 105 lines, 21 ignored<br />#0&nbsp; 0x7FC144227387<br />#1&nbsp; 0x1216CFD in __m_errors_MOD_msg_hndl<br />#2&nbsp; 0xC4E901 in chkinp_<br />#3&nbsp; 0x411A3B in MAIN__ at abinit.F90:416<br /><br />&nbsp;chkinp : ERROR -<br />&nbsp; When GPU is in use (use_gpu_cuda=1), ngfft(4:6) must be equal to ngfft(1:3) !<br />&nbsp; Action: suppress ngfft in input file or change it.<br /><br />--- !ERROR<br />message: |<br />&nbsp; &nbsp; Checking consistency of input data against itself gave 1 inconsistencies.<br />src_file: chkinp.F90<br />src_line: 3003<br />...<br /></code></pre></div><br /><br />Any help is greatly appreciated.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Mon Jul 14, 2014 10:18 pm</strong></div>
				<div class="author">by <strong>jbeuken</strong></div>
				<div class="content">Hi,<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>chkinp : ERROR -<br />&nbsp; When GPU is in use (use_gpu_cuda=1), ngfft(4:6) must be equal to ngfft(1:3) !<br />&nbsp; Action: suppress ngfft in input file or change it.<br /></code></pre></div><br /><br />Have you done a few things in relation to the suggested action ?<br /><br /><br />another general remark : you use a lot of not officially tested &quot;options&quot; on our test farm  :<br />for example :<br />- levmar ( not tested nightly )<br />- magma 1.5 beta   ( we test cuda with magma 1.2.1 )<br />- GPU + scalapack + OMP  ( we don't use GPU and OMP together )<br />- the test suite does not covered the scalapack part of code then scalapack is not tested, only the compilation is OK<br />- cuda 6 ( we use CUDA 4.2 and CUDA 5 )<br />- gcc 4.9.0  ( ok, it seems mature but it's a &quot;zero&quot; version )<br />- there are only 4 GPU tests  tested in the testsuite on our test farm ( for example, tests &quot;fast&quot; are not tester on the CUDA bot because references are different…)<br />  ( see : <!-- m --><a class="postlink" href="http://buildbot.abinit.org/builders/buda_gcc46_cuda/builds/2541/steps/newtests/logs/summary">http://buildbot.abinit.org/builders/bud ... gs/summary</a><!-- m -->)<br /><br />I can understand that you try to get a &quot;fast&quot; ABINIT version for production but it's a very complicated configuration…<br /><br />regards<br /><br />jmb</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Tue Jul 15, 2014 11:00 pm</strong></div>
				<div class="author">by <strong>roginovicci</strong></div>
				<div class="content">Is it possible to talk about fast configuration when code compiled with gnu C? I've found PGI or Intel compilators produces boost in performance up to 70%. That was a couple years thought. <br /><br />I'm not sure topic starter use linux platform, but I can assume based on my experience that best linux distros for abinit is redhat/centos or debian. I've found some problem using abinit with arch linux (same problems could occur in fedora or ubuntu) because its testing distros in fact. Anyway here is part of my script working quite well with cuda.<br /><br />export NVCC=&quot;$CUDA/bin/nvcc&quot;                                                                                                                                    <br />export FC=$MPICH2/bin/mpiifort                                                                                                                                  <br />export CC=$MPICH2/bin/mpiicc                                                                                                                                    <br />export CXX=$MPICH2/bin/mpiicpc                                                                                                                                  <br />./configure --prefix=/opt/abinit --enable-mpi --enable-mpi-io \                                                                                 <br /> --with-linalg-incs=&quot;-I$INTEL_COMP/mkl/include&quot; \                                                                                                               <br /> --with-fft-flavor=&quot;fftw3-mkl&quot; --with-fft-incs=&quot;-I$INTEL_COMP/mkl/include/fftw&quot; \                                                                               <br /> --with-fft-libs=&quot;-L$INTEL_COMP/mkl/lib/intel64 -lfftw3xf_intel&quot; \                                                                                              <br /> --with-linalg-flavor=&quot;mkl+magma&quot; \                                                                                                                             <br /> --with-linalg-libs=&quot;-L$INTEL_COMP/mkl/lib/intel64 -L/opt/magma/lib -lmagma -Wl,--start-group  -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -Wl,--start-group  -lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -Wl,--end-group -liomp5 -lpthread -limf -lsvml -lirc   -lmkl_sequential -lmkl_blacs_intelmpi_lp64 -lmkl_scalapack_lp64 &quot;  \<br /> --with-linalg-incs=&quot;-I/opt/magma/include&quot; \                                                                                                    <br /> --with-dft-flavor=&quot;atompaw+bigdft+libxc+wannier90&quot; \                                                                                                           <br /> --enable-gpu --with-gpu-flavor=cuda-double  --with-gpu-libs=&quot;-L$CUDA/lib64 -lcublas -lcufft -lcudart&quot; \                                                        <br /> --with-gpu-incs=&quot;-I$CUDA/include&quot; <br /><br />Can't help with levmar and OMP though, sorry.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Wed Jul 16, 2014 5:50 pm</strong></div>
				<div class="author">by <strong>Jordan</strong></div>
				<div class="content">Hi,<br /><br />I have exactly one of the problems above.<br />I compiled abinit-7.8.2 with cuda 4.2 and magam 1.2.1 (intel14+MKL11+openmpi-1.5.4) when I run the gpu tests (runtests.py gpu) test gpu_t01 succeeded but the other failed with the fft problem mentioned above (dimension 1:3 disagree with 4:6).<br />The ngfft is not set in the input file so abinit should be able to manage it correctly (I never use it anyway since abinit does it perfectly for me).<br />I've sent a mail to Marc and I'm waiting for his reply.<br />I would like to debug the code but I don't have any GUI debugger on the cluster so it will take time untill I find the bug and try to crrect it <img class="smilies" src="images/smilies/icon_e_smile.gif" alt=":)" title="Smile" /> <br /><br />Jordan</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Thu Jul 17, 2014 4:48 pm</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">Thanks for all the great replies and I am indeed using linux. Unfortunately I am out of town now. Further attempts will be done without levmar and openmp and I will report the results as soon as possible.<br /><br />If the fft problem appears again, any idea on how enforce the fft(1:3) to be equal to fft(4:6)? I am under the impression that the parameter ngfft is an array of three numbers only.<br /><br />Thank you.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Fri Jul 18, 2014 4:41 pm</strong></div>
				<div class="author">by <strong>Jordan</strong></div>
				<div class="content">I may have found what causes gpu tests/runs/ to fail.<br /><br />When generating ngfft, abinit checks 2 things at the end : if we use cuda then ngfft(4:6)=ngfft(1:3); and then if we use FFTW3 (or DFTI) update ngfft(4:5) to ngfft(1:2)+1 only if ngfft(1:2) is even. <br /><br />If you have a look in test gpu_t02, ngfft(1:2)=[12,12] so at the end of the routine ngfft(4:5)=[13,13].<br /><br />I am not an expert in FFT so what I would suggest is to force fftalg to 112 instead of 312  in the input file to avoid the last if condition.<br />I trie to add this fftalg 112 into gpu_t02/t02.in and it works.<br /><br />I'll try to find the answer regarding the use of FFTW3 with cuda....<br /><br />Cheers,<br /><br />Jordan</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Sat Jul 19, 2014 4:54 pm</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">I have recompiled abinit 7.8.1 without openmp and levmar, and have downgrade magma and cuda to version 1.2.1 and 5.0 respectively.<br /><br />Following the advice of Jordan. I modified the parameter fftalg manually for the input files of the gpu tests according the values shown in the referenced output file. Here is the output:<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>&#91;sheng@theory3 tests&#93;$ ../../abinit-7.8.1/tests/runtests.py -t0 gpu<br />FortranCompiler: gfortran None<br />../../abinit-7.8.1/tests/runtests.py:279: UserWarning: Cannot find timeout executable at: /usr/bin/timeout<br />&nbsp; warn(&quot;Cannot find timeout executable at: %s&quot; % build_env.path_of_bin(&quot;timeout&quot;))<br />Test_suite directory already exists! Old files will be removed<br />Running ntests = 4, MPI_nprocs = 1, py_nthreads = 1...<br />&#91;gpu&#93;&#91;t01&#93;&#91;np=1&#93;: failed: relative error 2.512e-08 &gt; 9e-09<br />&#91;gpu&#93;&#91;t02&#93;&#91;np=1&#93;: succeeded<br />&#91;gpu&#93;&#91;t03&#93;&#91;np=1&#93;: failed: relative error 0.7398 &gt; 0.08<br />&#91;gpu&#93;&#91;t04&#93;&#91;np=1&#93;: failed: erroneous lines 177 &gt; 0<br />Test suite completed in 56.63 s (average time for test = 13.88 s, stdev = 13.23 s)<br />failed: 3, succeeded: 1, passed: 0, skipped: 0, disabled: 0<br />Suite&nbsp; &nbsp;failed&nbsp; passed&nbsp; succeeded&nbsp; skipped&nbsp; disabled&nbsp; run_etime&nbsp; tot_etime<br />gpu&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3&nbsp; &nbsp; &nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1&nbsp; &nbsp; &nbsp; &nbsp; 0&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0&nbsp; &nbsp; &nbsp; 55.51&nbsp; &nbsp; &nbsp; 56.05<br />Test suite results in HTML format are available in Test_suite/suite_report.html<br /></code></pre></div><br /><br />The errors are larger than the tests' tolerance but at least the tests can be run, though I don't know about error of the fourth tests.<br /><br />By the ways, by some experimenting I found that the fftw cannot be used together with Cuda (when fflalg=312). For any calculation using Cuda I have to modify fftalg to either 112 or 401. What puzzles me is that fftalg should be of no importance when cuda is enabled according to the documantation of Abinit.<br /><br />The question now is (I cannot find it in the tutorial):<br />What is the command I should use when I am using the cuda-enabled abinit? Is it just a simple normal serial abinit command and abinit will automatically distribute the workload among the gpu cores, or I should use the mpirun -np N command where N is the allocated gpu cores?<br />And how can I confirm that Abinit is indeed using Cuda apart of examining the parameter use_gpu_cuda in the output file?<br /><br />Thank you.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Sun Jul 20, 2014 11:21 pm</strong></div>
				<div class="author">by <strong>jbeuken</strong></div>
				<div class="content">Hi,<br /><br /><blockquote class="uncited"><div>What is the command I should use when I am using the cuda-enabled abinit?</div></blockquote><br />in our test farm, the bot has 4 GPU Tesla C1060 and 2 Quad cores Xeon,<br />we start the GPU tests with &quot;mpirun -np=1 ...&quot; (and I think that we use only one card )<br /><br /><blockquote class="uncited"><div>And how can I confirm that Abinit is indeed using Cuda apart of examining the parameter use_gpu_cuda in the output file?</div></blockquote><br /><br />in the stdout, we found ( but it's not the proof that we use the GPU, but it's a good beginning <img class="smilies" src="images/smilies/icon_e_wink.gif" alt=";-)" title="Wink" /> )<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>&nbsp;setdevice_cuda : COMMENT -<br />&nbsp; GPU 0 has been properly initialized, continuing...<br /><br />&nbsp;________________________________________________________________________________<br />&nbsp;________________________ Graphic Card Properties _______________________________<br /><br />&nbsp; &nbsp; Device&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0 : Tesla C1060<br />&nbsp; &nbsp; Revision number:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1.3<br />&nbsp; &nbsp; Total amount of global memory:&nbsp; 4095.8 Mbytes<br />&nbsp; &nbsp; Clock rate:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1.3 GHz<br />&nbsp; &nbsp; Max GFLOP:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;311 GFP<br />&nbsp; &nbsp; Total&nbsp; constant memory:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 65536 bytes<br />&nbsp; &nbsp; Shared memory per block:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;16384 bytes<br />&nbsp; &nbsp; Number of registers per block:&nbsp; &nbsp;16384<br /><br />&nbsp;________________________________________________________________________________</code></pre></div><br /><br />my 5¢</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Mon Jul 21, 2014 5:17 am</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">Thanks jbeuken for your quick reply. It is will be great if anyone can elucidate me on the following:<br /><br />1. Since the command given is 'mpirun -np 1 ...' and only one card is used, can I assume that the variable N in 'mpirun -np N ...' refers to the number of gpu cards instead of number of cores?<br /><br />2. Actually I am now reading tutorial GSPW where the parameters such as paral_kgb, autoparal, max_ncpus, npband, npfft and npkpt are used. Are these parameters still apply when gpu is enabled? In order words, does KGB parallelization scheme works in gpu and we have to define the number or processors (or gpu cores) needed on each level of the KGB parallelization as described in the tutorial? Or is it automatically done by abinit in gpu?<br /><br />3. I am doing a gou calculation with a Quadro K600 with a stated maximum floating point operation of over 300 GFLOPS. However the graphic card section in the log file shows that the card is operating at 7 GFLOPS only. The time I use to do the tutorial tgspw_02.files is about 2500 secs, which is even longer than the serial calculation which takes only about 1800 secs. I have tried on 3 workstations equiped with the same card model with similar amount of time consumed. What could have possibly goes wrong?<br /><br />Thanks all this is sure a responsive forum.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Mon Jul 21, 2014 9:35 pm</strong></div>
				<div class="author">by <strong>Jordan</strong></div>
				<div class="content"><blockquote><div><cite>sheng wrote:</cite>1. Since the command given is 'mpirun -np 1 ...' and only one card is used, can I assume that the variable N in 'mpirun -np N ...' refers to the number of gpu cards instead of number of cores?<br /></div></blockquote><br /><br />I am doing some tries with GPU right now.  What is sure is &quot;mpirun -n X&quot; means X MPI process and not GPU (-n is equivalent to -np).<br />Each MPI process will try to allocate a GPU. If so, it will use it otherwise just use the CPU version. Therefore you should not use more CPU than the number of GPU you have (This is what Marc Torrent recommended to me and I confirm).<br /><br /><blockquote><div><cite>sheng wrote:</cite>2. Actually I am now reading tutorial GSPW where the parameters such as paral_kgb, autoparal, max_ncpus, npband, npfft and npkpt are used. Are these parameters still apply when gpu is enabled? In order words, does KGB parallelization scheme works in gpu and we have to define the number or processors (or gpu cores) needed on each level of the KGB parallelization as described in the tutorial? Or is it automatically done by abinit in gpu?<br /></div></blockquote><br /><br />Even if I use the GPU, I am still using the KGB parallelization. From what I understand, the parallelization is still valid and instead of doing the calculation for the given K-point/band group/fft group on the CPU, everything (as much as possible) is deported onto the GPU. Note that for a good scaling you need quite a big system.<br /><br /><blockquote><div><cite>sheng wrote:</cite>3. I am doing a gou calculation with a Quadro K600 with a stated maximum floating point operation of over 300 GFLOPS. However the graphic card section in the log file shows that the card is operating at 7 GFLOPS only. The time I use to do the tutorial tgspw_02.files is about 2500 secs, which is even longer than the serial calculation which takes only about 1800 secs. I have tried on 3 workstations equiped with the same card model with similar amount of time consumed. What could have possibly goes wrong?<br /></div></blockquote><br />I'll do the test and let you know. Maybe the frequency of yur GPU is reduced if it has nothing to do.<br /><br />EDIT : I did the test. Abinit reports<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>________________________________________________________________________________<br />&nbsp;________________________ Graphic Card Properties _______________________________<br />&nbsp;<br />&nbsp; &nbsp; Device&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0 : Tesla M2090<br />&nbsp; &nbsp; Revision number:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2.0&nbsp; <br />&nbsp; &nbsp; Total amount of global memory:&nbsp; 5375.4 Mbytes<br />&nbsp; &nbsp; Clock rate:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1.3 GHz<br />&nbsp; &nbsp; Max GFLOP:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;166 GFP<br />&nbsp; &nbsp; Total&nbsp; constant memory:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 65536 bytes<br />&nbsp; &nbsp; Shared memory per block:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;49152 bytes<br />&nbsp; &nbsp; Number of registers per block:&nbsp; &nbsp;32768<br />&nbsp;<br />&nbsp;________________________________________________________________________________<br /></code></pre></div><br />And the calculation on 1GPU is <br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>overall_cpu_time:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;786.0<br />overall_wall_time:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;806.9<br /></code></pre></div><br />Note that Nvidia says more than 1TFLOPS for this card when Abinit only reports 166GFLOPS. I don't know how this value is obtained, though.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Mon Jul 21, 2014 9:43 pm</strong></div>
				<div class="author">by <strong>Jordan</strong></div>
				<div class="content"><blockquote><div><cite>sheng wrote:</cite>I have recompiled abinit 7.8.1 without openmp and levmar, and have downgrade magma and cuda to version 1.2.1 and 5.0 respectively.<br /><br />The errors are larger than the tests' tolerance but at least the tests can be run, though I don't know about error of the fourth tests.<br /></div></blockquote><br />It means the output file has 177 lines that differ from the reference (regardless the tolerence) and only &quot;0&quot; different line are allowed.<br />We only test the GPU test on one bot so we don't know much about the tolerences we should allow. I guess it is very GPU dependent. <br /><blockquote><div><cite>sheng wrote:</cite>By the ways, by some experimenting I found that the fftw cannot be used together with Cuda (when fflalg=312). For any calculation using Cuda I have to modify fftalg to either 112 or 401. What puzzles me is that fftalg should be of no importance when cuda is enabled according to the documantation of Abinit.<br /></div></blockquote><br />Yes you have to do it as I suggested but it has no impact since the FFT is done by the GPU with cuFFT(as far as I understand). This is a tiny bug and we are working on it. Hopefully it will be corrected for the next release.<br />[/quote]<br /><br /><blockquote class="uncited"><div>The question now is (I cannot find it in the tutorial):<br />What is the command I should use when I am using the cuda-enabled abinit? Is it just a simple normal serial abinit command and abinit will automatically distribute the workload among the gpu cores, or I should use the mpirun -np N command where N is the allocated gpu cores?<br />And how can I confirm that Abinit is indeed using Cuda apart of examining the parameter use_gpu_cuda in the output file?</div></blockquote><br />If you have compiled Abinit with GPU support AND a GPU is available at the runtime AND the calculation can be port onto the GPU then Abinit automatically uses the GPU.<br />Use mpirun -n/np N for N MPI processes, each one will try to allocate a GPU. The best choice is N=number of GPU you want to use (each MPI process uses one GPU)<br /><br />Jordan</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Tue Jul 22, 2014 4:49 am</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">Thanks Jordan for your quick information.<br /><br /><blockquote class="uncited"><div>Even if I use the GPU, I am still using the KGB parallelization. From what I understand, the parallelization is still valid and instead of doing the calculation for the given K-point/band group/fft group on the CPU, everything (as much as possible) is deported onto the GPU. Note that for a good scaling you need quite a big system.</div></blockquote><br /><br />Does it means that unlike in cpu, the distribution of calculation over K-point/band group/fft is automatically handled in gpu (means I don't have to care about the variable max_ncpus, npband, npfft or npkpt anymore)?<br /><br /><blockquote class="uncited"><div>Maybe the frequency of yur GPU is reduced if it has nothing to do.</div></blockquote><br /><br />The report from abinit shows:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>&nbsp;________________________________________________________________________________<br />&nbsp;________________________ Graphic Card Properties _______________________________<br /><br />&nbsp; &nbsp; Device&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0 : Quadro K600<br />&nbsp; &nbsp; Revision number:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.0<br />&nbsp; &nbsp; Total amount of global memory:&nbsp; 1023.3 Mbytes<br />&nbsp; &nbsp; Clock rate:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.9 GHz<br />&nbsp; &nbsp; Max GFLOP:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;7 GFP<br />&nbsp; &nbsp; Total&nbsp; constant memory:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 65536 bytes<br />&nbsp; &nbsp; Shared memory per block:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;49152 bytes<br />&nbsp; &nbsp; Number of registers per block:&nbsp; &nbsp;65536<br /></code></pre></div><br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>overall_cpu_time:&nbsp; &nbsp; &nbsp; &nbsp; 3335.0<br />overall_wall_time:&nbsp; &nbsp; &nbsp; &nbsp; 3356.0<br /></code></pre></div><br /><br />The Max GFLOP is unreasonably low as shown above and the time taken is over 3300 secs, significantly longer than a serial calculation without gpu. Since the calculation is over 107 gold atoms, I consider the scaling should be good enough to compensate for the overhead. The gpu timing taken would defeat the whole purpose of running cuda.<br /><br />A thing to ask though, does the benchtest for gpu cuda comparable to the conventional parallel cpu mpi used by abinit?</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda&nbsp;&nbsp;<span style="color: #006600">[SOLVED]</span></h3>
				<div class="date">Posted: <strong>Tue Jul 22, 2014 4:07 pm</strong></div>
				<div class="author">by <strong>Jordan</strong></div>
				<div class="content"><blockquote><div><cite>sheng wrote:</cite>Does it means that unlike in cpu, the distribution of calculation over K-point/band group/fft is automatically handled in gpu (means I don't have to care about the variable max_ncpus, npband, npfft or npkpt anymore)?<br /></div></blockquote><br /><br />No, according to my  understanding, you still have to define those parameters but instead of using a large number of cpu for npband you may want to reduce it.<br />For example, if you have 5 GPUs and 10 kpt, 200 bands, what I do is put npkpt to 5 and npband to 1 with bandpp to 2 or 4. when for a CPU calculation you woud like to have npkpt 5 npband 10 bandpp 2 npfft 1 for 50 cpus. In this example, the calculation on 50 cpus would be a little more than twice faster (I hope).<br />If you have 10 GPUs and 1000 bands you may consider to pu npband to 2 to split the band load. So the parallelization is the same but with &quot;small numbers&quot; I did not do benchmarks but I think GPUs should handle easier larger values of bandpp.<br />BTW, I never use the max_ncpus variable and always define myself the np* variables.<br /><br /><blockquote class="uncited"><div>The report from abinit shows:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>&nbsp;________________________________________________________________________________<br />&nbsp;________________________ Graphic Card Properties _______________________________<br /><br />&nbsp; &nbsp; Device&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0 : Quadro K600<br />&nbsp; &nbsp; Revision number:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.0<br />&nbsp; &nbsp; Total amount of global memory:&nbsp; 1023.3 Mbytes<br />&nbsp; &nbsp; Clock rate:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.9 GHz<br />&nbsp; &nbsp; Max GFLOP:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;7 GFP<br />&nbsp; &nbsp; Total&nbsp; constant memory:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 65536 bytes<br />&nbsp; &nbsp; Shared memory per block:&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;49152 bytes<br />&nbsp; &nbsp; Number of registers per block:&nbsp; &nbsp;65536<br /></code></pre></div><br /></div></blockquote><br />According to google, your K600 quadro gpus is &quot;graphic card&quot; - meaning with outputs for diplays. I don't know your configuration but can you confirm you use your GPU only for the calculations and not for you screen/desktop ? If you only have one GPU for both, then that might be the reason. You must have a dedicated GPU for calculations, otherwise I have no clue. What driver are you using ? the last one from Nvidia website ?<br /><br /><blockquote class="uncited"><div>Since the calculation is over 107 gold atoms, I consider the scaling should be good enough to compensate for the overhead. The gpu timing taken would defeat the whole purpose of running cuda.</div></blockquote><br />I agree with you. I did not try the test on on CPU to get the speed up on GPU but after running some other cases with 32 atoms, I still have good timing (6 GPUs are faster than 24 CPUs)<br />The timing reported by Abinit is the wall time used by CPUs so if a GPU does a task in 10s instead of 100s on the CPU, you will have wall cpu time=10 since from the begin to the end the CPU has run for 10s. The timings are thus comparables between GPUs/CPUs</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Tue Jul 22, 2014 9:03 pm</strong></div>
				<div class="author">by <strong>jbeuken</strong></div>
				<div class="content">Hi everybody,<br /><br />Thank you Jordan for your relevant answers…<br /><br />And , effectively, &quot;mpirun -np=1&quot; is only applicable to &quot;core&quot; and , <br />in OUR GPU TESTS FROM OUR TESTSUITE,  there is only one core with one GPU card <br />but still managed by the magma level ! <br /><br />Then, in production, with correct parameters ( paral_kgb, autoparal, max_ncpus, npband, npfft,.. ), <br />you can potentially use all resources of your &quot;machine&quot;... <img class="smilies" src="images/smilies/icon_rolleyes.gif" alt=":roll:" title="Rolling Eyes" /> <br /><br />I know that there are some teams (   <img class="smilies" src="images/smilies/icon_e_confused.gif" alt=":?" title="Confused" />  ) using ABINIT, can reach to use several multicore CPU with many GPU cards in production with a good speedup…<br />BUT it's not so easy…<br /><br />the good new, it's there are some ABINIT' developers work hard to optimize / facilitate parallelism ( core/CPU/node/GPU/MIC/... ) in ABINIT: a little patience …<br /><br />my 50¢<br /><br />jmb</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Wed Jul 23, 2014 5:28 am</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">Thanks all.<br /><br />My quadro K600 is indeed used for both display and computing. I have tried to get rid of display by booting into cmd mode but with the same low Max FLOP. Maybe this is purely related to card itself and I have submitted a question on Nvidia forum. Thank you all for your great information and patience with me.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Wed Jul 23, 2014 5:25 pm</strong></div>
				<div class="author">by <strong>sheng</strong></div>
				<div class="content">Sorry to bump this thread again, but I have read that Nvidia has out stripped double precision floating point operations from all Kepler-based Quadros, concentrating instead on single precision.<br /><br />In light of that I change the configuration: with_gpu_flavor=&quot;cuda-single&quot; instead of cuda-double. However Abinit demands the double-precision version when I tried run it.<br /><br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>Input variables use_gpu_cuda is on but abinit hasn't been built<br />&nbsp; &nbsp; &nbsp; &nbsp;with (double precision) gpu mode enabled !<br />&nbsp; &nbsp; &nbsp; &nbsp;Action : change the input variable use_gpu_cuda<br />&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; or re-compile ABINIT with double-precision Cuda enabled.<br /></code></pre></div><br /><br />Does that means that Abinit only works with the double-precision version?</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: Problem with cuda</h3>
				<div class="date">Posted: <strong>Thu Jul 24, 2014 6:40 pm</strong></div>
				<div class="author">by <strong>Jordan</strong></div>
				<div class="content"><blockquote><div><cite>sheng wrote:</cite><br />Does that means that Abinit only works with the double-precision version?</div></blockquote><br /><br />I don't really know, but in the code, file src/57_iovars/chkinp.F90, there is<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>2698 #ifndef HAVE_GPU_CUDA_DP<br />2699&nbsp; &nbsp; &nbsp; write(message,'(10a)') ch10,&amp;<br />2700 &amp;&nbsp; &nbsp; &nbsp;' invars0: ERROR -',ch10,&amp;<br />2701 &amp;&nbsp; &nbsp; &nbsp;'&nbsp; &nbsp;Input variables use_gpu_cuda is on but abinit hasn''t been built',ch10,&amp;<br />2702 &amp;&nbsp; &nbsp; &nbsp;'&nbsp; &nbsp;with gpu mode in DOUBLE PRECISION enabled !',ch10,&amp;<br />2703 &amp;&nbsp; &nbsp; &nbsp;'&nbsp; &nbsp;Action : change the input variable use_gpu_cuda',ch10,&amp;<br />2704 &amp;&nbsp; &nbsp; &nbsp;'&nbsp; &nbsp;or re-compile ABINIT with double precision Cuda enabled.'<br />2705&nbsp; &nbsp; &nbsp; call wrtout(std_out,message,'COLL')<br />2706&nbsp; &nbsp; &nbsp; ierr=ierr+1<br />2707 #endif<br /></code></pre></div><br />You can find the same code in 57_iovars/invars0.F90 (look for HAVE_GPU_CUDA_DP)<br />So the error is triggered any time you don't use double precision.<br />You may try to uncomment those 2 parts and compile again in single precision.<br />A quick look in the source file makes me feel that the code will run with precision of 1e-7 instead of 1e-12 in DP mode.<br />You should check carefully your results if that works before going to productoin of course.<br />If the single precision feature has been disable, it might have a reason... but what reason...don't know <img class="smilies" src="images/smilies/icon_e_smile.gif" alt=":)" title="Smile" /><br /><br />Jordan<br /><br />EDIT: BTW, if you don't want to use your K600 for your display, you need an other GPU for it (or IGP on recent intel cpus). You can also try to complitely unplug your display and access the compurter via ssh. If it still does not desactivate the GPU, remove all X11 service at boot stage.</div>
			</div>
			<hr />
			</div>

	<div id="page-footer" class="page-footer">
		<div class="page-number">All times are <span title="Europe/Brussels">UTC+02:00</span><br />Page <strong>1</strong> of <strong>1</strong></div>
			<div class="copyright">
				<p>Powered by <a href="https://www.phpbb.com/">phpBB</a>&reg; Forum Software &copy; phpBB Limited
				</p>
							</div>
	</div>
</div>

</body>

<!-- Mirrored from forum.abinit.org/viewtopic.php?f=3&t=2729&view=print by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 21 Sep 2024 01:00:29 GMT -->
</html>
