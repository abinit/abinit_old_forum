<!DOCTYPE html>
<html dir="ltr" lang="en-gb">

<!-- Mirrored from forum.abinit.org/viewtopic.php?f=3&t=1851&view=print by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 21 Sep 2024 02:36:02 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
<meta charset="utf-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="robots" content="noindex" />

<title>ABINIT Discussion Forums &bull; abinit6.12.3 crashes in more than 1 node (Intel Comp)</title>

<link href="styles/flat-style/theme/print.css" rel="stylesheet">
<link href="styles/flat-style/theme/bidi.css" rel="stylesheet">
</head>
<body id="phpbb" class="ltr">
<div id="wrap" class="wrap">
	<a id="top" class="top-anchor" accesskey="t"></a>

	<div id="page-header">
		<h1>ABINIT Discussion Forums</h1>
		<p>The meeting place for ABINIT users and developers<br /><a href="index.html">https://forum.abinit.org/</a></p>

		<h2>abinit6.12.3 crashes in more than 1 node (Intel Comp)</h2>
		<p><a href="viewtopicff1d.html?f=3&amp;t=1851">https://forum.abinit.org/viewtopic.php?f=3&amp;t=1851</a></p>
	</div>

	<div id="page-body" class="page-body">
		<div class="page-number">Page <strong>1</strong> of <strong>1</strong></div>
					<div class="post">
				<h3>abinit6.12.3 crashes in more than 1 node (Intel Comp)</h3>
				<div class="date">Posted: <strong>Tue Oct 09, 2012 12:43 pm</strong></div>
				<div class="author">by <strong>ivasan</strong></div>
				<div class="content">Hello Everyone,<br /><br />I have compiled abinit6.12.3 without errors and it runs properly when I am only using one computing node in our cluster (the computer node has 2 hexacore processors). The problem arises when I try to use more than one computing node: it crashes at the very beginning.<br /><br />In the attached files there is all the information I could gather:<br /><br />- File 'config.log': log file from the configuration of abinit. In brief: I used Intel MPi 4.0.3, Intel Compilers XE2013, Intel MKL BLACS and Intel MKL FFTW3<br /><br />- File 'simul.log': log file of the simulation that crashes. I used several options within mpirun to get the information related to MPI calls since it seems that the problem is there ( -v -check_mpi -genv I_MPI_DEBUG 5).<br /><br />- File 'abinit.in': the input file of the simulation I am trying to run, just in case it is meaningful. In brief, I want to generate the WFK necessary for a subsequent run to generate a KSS file. This input file works fine if I only use one computing node, so I don't think that the problem is here.<br /><br />It seems from the log that the errors are related to MPI since there are messages such as:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>&#91;23&#93; ERROR: LOCAL:MPI:CALL_FAILED: error<br />&#91;23&#93; ERROR:&nbsp; &nbsp; Null communicator.<br />&#91;23&#93; ERROR:&nbsp; &nbsp; Error occurred at:<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;mpi_comm_rank_(comm=MPI_COMM_NULL, *rank=0x29319b8, *ierr=0x7fff83fabb74)<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;initmpi_grid_ (/home/ivasan/programas/abinit/abinit-6.12.3b/src/51_manage_mpi/initmpi_grid.F90:178)<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;invars1_ (/home/ivasan/programas/abinit/abinit-6.12.3b/src/57_iovars/invars1.F90:1015)<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;invars1m_ (/home/ivasan/programas/abinit/abinit-6.12.3b/src/57_iovars/invars1m.F90:186)<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;m_ab6_invars_mp_ab6_invars_load_ (/home/ivasan/programas/abinit/abinit-6.12.3b/src/57_iovars/m_ab6_invars_f90.F90:548)<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;MAIN__ (/home/ivasan/programas/abinit/abinit-6.12.3b/src/98_main/abinit.F90:260)<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;main (/home/ivasan/programas/abinit/abinit-6.12.3b/bin/abinit)<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;(/lib64/libc-2.5.so)<br />&#91;23&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;(/home/ivasan/programas/abinit/abinit-6.12.3b/bin/abinit)<br /></code></pre></div><br /><br />I will appreciate if anyone could give me a hint about what can I check/modify in order to solve this problem.<br /><br />Thank you very much in advance for your answers and your time.<br /><br />Kind regards,<br /><br />Iván</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: abinit6.12.3 crashes when using several computing nodes</h3>
				<div class="date">Posted: <strong>Tue Oct 09, 2012 1:42 pm</strong></div>
				<div class="author">by <strong>pouillon</strong></div>
				<div class="content">Your problem very likely comes from a bug of Intel 13.0 compilers. In general, I strongly advise against using *.0 versions of Intel compilers, as they usually contain many bugs.<br /><br />If you really need to use Intel compiilers, recompiling everything with a recent Intel 12.1 installation should solve the issue. I'm currently using it on some machines without any major issue.<br /><br />Please also remember that &quot;more recent&quot; doesn't always mean &quot;better&quot;. New major versions of any software usually have teething problems, and you should use them only if you are willing to contribute to their debugging.</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: abinit6.12.3 crashes when using several computing nodes</h3>
				<div class="date">Posted: <strong>Tue Oct 09, 2012 2:12 pm</strong></div>
				<div class="author">by <strong>ivasan</strong></div>
				<div class="content">Dear Yann,<br /><br />Thanks for your fast response. I will try to use the version of the Intel compilers you mention.<br /><br />I will let you know how it goes.<br /><br />Thanks!!!<br /><br />Iván</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: abinit6.12.3 crashes when using several computing nodes</h3>
				<div class="date">Posted: <strong>Fri Oct 26, 2012 4:26 pm</strong></div>
				<div class="author">by <strong>ivasan</strong></div>
				<div class="content">Dear Yann,<br /><br />I have been doing some more tests and somehow I managed to run the job in more than one computing node ... but I am quite surprised with the solution I found.<br /><br />It seems that the problem was in the input file, not in the configuration of my cluster. The input file of the simulation I want to run has these values for ionmov and optcell:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>ionmov=2<br />optcell=2<br /></code></pre></div><br />With these values abinit only runs in one computing node (in both 6.10.3 and 6.12.3). However, if I change optcell to<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>ionmov=2<br />optcell=0<br /></code></pre></div><br />it perfectly runs in more than one computing node.<br /><br />Is this behavior normal? I couldn't find any related warning in the manual about the limitations of optcell.<br /><br />Best regards,<br /><br />Iván</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: [SOLVED] abinit6.12.3 crashes in more than 1 node (Intel</h3>
				<div class="date">Posted: <strong>Fri Oct 26, 2012 5:59 pm</strong></div>
				<div class="author">by <strong>ivasan</strong></div>
				<div class="content">Dear Yann,<br /><br />I managed to solve the problem. It seems that it was related to the stack.<br /><br />The solution was adding<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>FCFLAGS_EXTRA=&quot; -heap-arrays&quot; CFLAGS_EXTRA=&quot;-heap-arrays&quot;</code></pre></div><br /><br />In the configure, which is now:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>./configure --prefix=&quot;/home/ivasan/programas/abinit/abinit-6.12.3&quot; CC=&quot;/opt/intel/impi/4.1.0/intel64/bin/mpiicc&quot; CXX=&quot;/opt/intel/impi/4.1.0/intel64/bin/mpiicpc&quot; FC=&quot;/opt/intel/impi/4.1.0/intel64/bin/mpiifort&quot; --enable-mpi --enable-mpi-io&nbsp; MPI_RUNNER=&quot;/opt/intel/impi/4.1.0/intel64/bin/mpirun&quot; --with-mpi-libs=&quot;-L/opt/intel/impi/4.1.0/intel64/lib -lmpi&quot; --with-mpi-incs=&quot;-I/opt/intel/impi/4.1.0/intel64/include&quot; --with-linalg-flavor=&quot;mkl+scalapack&quot; --with-linalg-incs=&quot;-I/opt/intel/mkl/include/intel64/&quot; --with-fft-flavor=&quot;fftw3-mkl&quot; --with-fft-incs=&quot;-I/opt/intel/mkl/include/fftw&quot; --with-fft-libs=&quot;-L/opt/intel/mkl/interfaces/fftw3xf -lfftw3xf_intel&quot; --enable-gw-dpc --with-linalg-libs=&quot;-L/opt/intel/mkl/lib/intel64 -lmkl_blas95_lp64 -lmkl_lapack95_lp64 -lmkl_scalapack_lp64 -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lmkl_blacs_intelmpi_lp64 -lpthread -lm&quot; FCFLAGS_EXTRA=&quot; -heap-arrays&quot; CFLAGS_EXTRA=&quot;-heap-arrays&quot;</code></pre></div><br /><br />As you can see, I use:<br />- Intel Compilers XE2013 (V13.0)<br />- Intel MPI 4.1<br />- LAPACK, BLACS, SCALAPACK, FFTW from Intel MKL 11.0<br /><br />As far as I could have tested, there are no more problems.<br /><br />However, I am not quite sure about the option &quot;-heap-arrays&quot; in the compilation. I had a bad experience with other program: the jobs consumed all the memory at the computing nodes, and the nodes crashed.<br /><br />Do you think that this can also happen in abinit?<br /><br />Best regards,<br /><br />Iván</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: SOLVED-abinit6.12.3 crashes in more than 1 node (Intel C</h3>
				<div class="date">Posted: <strong>Sun Oct 28, 2012 6:44 pm</strong></div>
				<div class="author">by <strong>Alain_Jacques</strong></div>
				<div class="content">Hi Ivan,<br /><br />I assume that you solved the problem by using the heap instead of the stack when calling functions - stack is the default for recent compilers. OK fine ... that's the former behaviour, nothing wrong here.<br />But using the stack has a few advantages (speed, sort of garbage collection, sort of protection against memory leaks, ...) so it's a bit of a pity to revert to heap before trying to extend the stacksize if your cluster nodes crash because the memory allocated to the stack is exhausted. Did you try to use <div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>ulimit -s unlimited</code></pre></div> - to be included in your preferred batch script. Or simply see what <div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>ulimit -a</code></pre></div> on one node returns? IMHO this cures half the obscure segfault cases on Unix boxes<br /><br />Kind regards,<br /><br />Alain</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: SOLVED-abinit6.12.3 crashes in more than 1 node (Intel C</h3>
				<div class="date">Posted: <strong>Wed Oct 31, 2012 10:06 am</strong></div>
				<div class="author">by <strong>ivasan</strong></div>
				<div class="content">Hi Alain,<br /><br />Thanks for your suggestion. I saw it in some other places, but in my case<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>ulimit -s ulimited</code></pre></div><br />does not work. Before using the -heap-arrays option, I added this command to my .bash_profile and this is what I get with 'ulimit -a' in any of the nodes on my cluster<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>core file size&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (blocks, -c) 0<br />data seg size&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(kbytes, -d) unlimited<br />scheduling priority&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(-e) 0<br />file size&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(blocks, -f) unlimited<br />pending signals&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(-i) 1587200<br />max locked memory&nbsp; &nbsp; &nbsp; &nbsp;(kbytes, -l) 2000000<br />max memory size&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(kbytes, -m) unlimited<br />open files&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (-n) 1024<br />pipe size&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (512 bytes, -p) 8<br />POSIX message queues&nbsp; &nbsp; &nbsp;(bytes, -q) 819200<br />real-time priority&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (-r) 0<br />stack size&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (kbytes, -s) unlimited<br />cpu time&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(seconds, -t) unlimited<br />max user processes&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (-u) 1587200<br />virtual memory&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (kbytes, -v) unlimited<br />file locks&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (-x) unlimited</code></pre></div><br />but abinit was still not running in more than one node.<br /><br />I have experienced this problem with another similar program I am using, and I could solve it after some &quot;soft coding&quot;: I had to add this routine:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>#include &lt;sys/time.h&gt; <br />#include &lt;sys/resource.h&gt; <br />#include &lt;stdio.h&gt; <br />void stacksize_() <br />{ <br />int res; <br />struct rlimit rlim; <br /><br />getrlimit(RLIMIT_STACK, &amp;rlim); <br />printf(&quot;Before: cur=%d,hard=%d\n&quot;,(int)rlim.rlim_cur,(int)rlim.rlim_max); <br /><br />rlim.rlim_cur=RLIM_INFINITY; <br />rlim.rlim_max=RLIM_INFINITY; <br />res=setrlimit(RLIMIT_STACK, &amp;rlim); <br /><br />getrlimit(RLIMIT_STACK, &amp;rlim); <br />printf(&quot;After: res=%d,cur=%d,hard=%d\n&quot;,res,(int)rlim.rlim_cur,(int)rlim.rlim_max); <br />} </code></pre></div><br />to the compilation, and call the function stacksize() at the very beginning of the main file of the program that had the stack problem. This worked in that case (by the way, in that case the option 'ulimit -s unlimited' didn't work either), so I didn't have to use the option '-heap-arrays' in the compilation.<br /><br />I tried to find out how to implement this method in abinit ... but I am quite new with abinit and I don't understand well its structure.<br /><br />I am aware of the 'dangers' of the option '-heap-arrays', but at the moment it is the only solution that I have. If you or anyone else can help with this in order to avoid '-heap-arrays' it will be great.<br /><br />Best regards,<br /><br />Iván</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: abinit6.12.3 crashes in more than 1 node (Intel Comp)</h3>
				<div class="date">Posted: <strong>Wed Oct 31, 2012 5:40 pm</strong></div>
				<div class="author">by <strong>ivasan</strong></div>
				<div class="content">Hi all,<br /><br />I am still having the problem. When abinit compiled with &quot;-heap-arrays&quot; is about to finish, it crashes with the following message:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>m_wffile.F90:279:COMMENT<br />&nbsp; &nbsp;MPI/IO accessing FORTRAN file header: detected record mark length=4<br />&nbsp;ioarr: data written to disk file cSi216I3Jxo_TIM1_DEN<br />&nbsp;bonds_lgth_angles : about to open file cSi216I3Jxo_TIM1_GEO<br />APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)</code></pre></div><br /><br />It seems to be related with the bus of data transfer.<br /><br />Best regards,<br /><br />Iván</div>
			</div>
			<hr />
					<div class="post">
				<h3>Re: abinit6.12.3 crashes in more than 1 node (Intel Comp)</h3>
				<div class="date">Posted: <strong>Wed Oct 31, 2012 7:20 pm</strong></div>
				<div class="author">by <strong>ivasan</strong></div>
				<div class="content">Hello again,<br /><br />Definitively &quot;-heap-arrays&quot; is not a solution, I still get errors.<br /><br />Coming back to the compilation without this option:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>./configure --prefix=&quot;/home/ivasan/programas/abinit/abinit-6.12.3-stack&quot; CC=&quot;/opt/intel/impi/4.1.0/intel64/bin/mpiicc&quot; CXX=&quot;/opt/intel/impi/4.1.0/intel64/bin/mpiicpc&quot; FC=&quot;/opt/intel/impi/4.1.0/intel64/bin/mpiifort&quot; --enable-mpi --enable-mpi-io&nbsp; MPI_RUNNER=&quot;/opt/intel/impi/4.1.0/intel64/bin/mpirun&quot; --with-mpi-libs=&quot;-L/opt/intel/impi/4.1.0/intel64/lib -lmpi&quot; --with-mpi-incs=&quot;-I/opt/intel/impi/4.1.0/intel64/include&quot; --with-linalg-flavor=&quot;mkl+scalapack&quot; --with-linalg-incs=&quot;-I/opt/intel/mkl/include/intel64/&quot; --with-fft-flavor=&quot;fftw3-mkl&quot; --with-fft-incs=&quot;-I/opt/intel/mkl/include/fftw&quot; --with-fft-libs=&quot;-L/opt/intel/mkl/interfaces/fftw3xf -lfftw3xf_intel&quot; --enable-gw-dpc --with-linalg-libs=&quot;-L/opt/intel/mkl/lib/intel64 -lmkl_blas95_lp64 -lmkl_lapack95_lp64 -lmkl_scalapack_lp64 -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lmkl_blacs_intelmpi_lp64 -lpthread -lm&quot;</code></pre></div><br /><br />I have tried to run a very simple simulation (file abinit.2.in) of a supercell relaxation using 12 cores in two different nodes, but it crashes (I am using the LDA psp 14-Si.LDA.fhi). The very same simulation ends without problems when only one node is used.<br /><br />I have attached two different log files with some MPI information:<br />- simul.2.log: obtained with the mpirun options -v -genv I_MPI_DEBUG 100<br />- simul.2.checkmpi.log: obtained with mpirun options -check-mpi -v -genv I_MPI_DEBUG 100.<br /><br />With respect to the STATUS files after the simulation, some of them contain this information:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>Status file, with repetition rate&nbsp; 49, status number&nbsp; &nbsp; 10<br />&nbsp;<br />&nbsp; Level abinit&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;: call macroin2</code></pre></div><br />while other contain this:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>&nbsp;Status file, with repetition rate&nbsp; 49, status number&nbsp; &nbsp; 50<br />&nbsp;<br />&nbsp; Level abinit&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;: call driver&nbsp; &nbsp;<br />&nbsp; Level driver&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;: call gstateimg<br />&nbsp; Level gstateimg&nbsp; &nbsp; &nbsp; : enter&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<br />&nbsp; Level gstate&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;: call mover&nbsp; &nbsp; <br />&nbsp; Level scfcv&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; : call vtorho&nbsp; &nbsp;<br />&nbsp; istep&nbsp; &nbsp; &nbsp; =&nbsp; &nbsp; 1<br />&nbsp; Level vtorho(tf)&nbsp; &nbsp; &nbsp;: loop ikpt&nbsp; &nbsp; &nbsp;<br />&nbsp; isppol&nbsp; &nbsp; &nbsp;=&nbsp; &nbsp; 1<br />&nbsp; ikpt&nbsp; &nbsp; &nbsp; &nbsp;=&nbsp; &nbsp; 6</code></pre></div><br /><br />Now errors are from the processes of the slave node, and they point to gstate routine:<br /><div class="codebox"><p>Code: <a href="#" onclick="selectCode(this); return false;">Select all</a></p><pre><code>&#91;6&#93; ERROR: LOCAL:EXIT:SIGNAL: fatal error<br />&#91;6&#93; ERROR:&nbsp; &nbsp; Fatal signal 11 (SIGSEGV) raised.<br />&#91;6&#93; ERROR:&nbsp; &nbsp; Signal was encountered at:<br />&#91;6&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;gstate_ (/home/ivasan/programas/abinit/abinit-6.12.3-stack/src/95_drive/gstate.F90:1041)<br />&#91;6&#93; ERROR:&nbsp; &nbsp; After leaving:<br />&#91;6&#93; ERROR:&nbsp; &nbsp; &nbsp; &nbsp;mpi_comm_rank_(comm=MPI_COMM_WORLD, *rank=0x7fff1a744870-&gt;6, *ierr=0x7fff1a744874-&gt;MPI_SUCCESS)</code></pre></div><br /><br />Does anyone see anything wrong?<br /><br />Best regards,<br /><br />Iván</div>
			</div>
			<hr />
			</div>

	<div id="page-footer" class="page-footer">
		<div class="page-number">All times are <span title="Europe/Brussels">UTC+02:00</span><br />Page <strong>1</strong> of <strong>1</strong></div>
			<div class="copyright">
				<p>Powered by <a href="https://www.phpbb.com/">phpBB</a>&reg; Forum Software &copy; phpBB Limited
				</p>
							</div>
	</div>
</div>

</body>

<!-- Mirrored from forum.abinit.org/viewtopic.php?f=3&t=1851&view=print by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 21 Sep 2024 02:36:02 GMT -->
</html>
